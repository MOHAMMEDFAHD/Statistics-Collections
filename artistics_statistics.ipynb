{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "L-jZcNzuGje5"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# All the Stats Visualizations: The Ultimate Plot Parade\n",
        "# Designed for Google Colab – unleash statistical insanity\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import altair as alt\n",
        "import scipy.stats as stats\n",
        "from pandas.plotting import scatter_matrix, parallel_coordinates\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Load sample datasets\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "titanic = sns.load_dataset(\"titanic\")\n",
        "flights = sns.load_dataset(\"flights\")\n",
        "\n",
        "# Set style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# UNIVARIATE PLOTS\n",
        "fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
        "sns.histplot(iris['sepal_length'], kde=True, ax=axs[0,0])\n",
        "axs[0,0].set_title(\"Histogram + KDE\")\n",
        "sns.boxplot(x=iris['sepal_length'], ax=axs[0,1])\n",
        "axs[0,1].set_title(\"Boxplot\")\n",
        "sns.violinplot(x=iris['species'], y=iris['petal_length'], ax=axs[0,2])\n",
        "axs[0,2].set_title(\"Violin Plot\")\n",
        "sns.stripplot(x=tips['day'], y=tips['total_bill'], ax=axs[1,0])\n",
        "axs[1,0].set_title(\"Strip Plot\")\n",
        "sns.swarmplot(x=tips['day'], y=tips['total_bill'], ax=axs[1,1])\n",
        "axs[1,1].set_title(\"Swarm Plot\")\n",
        "sns.countplot(x=tips['day'], ax=axs[1,2])\n",
        "axs[1,2].set_title(\"Count Plot\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# BIVARIATE PLOTS\n",
        "sns.pairplot(iris, hue=\"species\")\n",
        "plt.suptitle(\"Pairplot\", y=1.02)\n",
        "plt.show()\n",
        "\n",
        "sns.jointplot(data=iris, x=\"sepal_length\", y=\"petal_length\", kind=\"kde\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation Heatmap (FIXED)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(iris.select_dtypes(include='number').corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# 3D Scatter Plot\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(iris['sepal_length'], iris['sepal_width'], iris['petal_length'], c=iris['species'].astype('category').cat.codes)\n",
        "ax.set_xlabel('Sepal Length')\n",
        "ax.set_ylabel('Sepal Width')\n",
        "ax.set_zlabel('Petal Length')\n",
        "plt.title(\"3D Scatter Plot\")\n",
        "plt.show()\n",
        "\n",
        "# Regression Plots\n",
        "sns.lmplot(x=\"total_bill\", y=\"tip\", hue=\"sex\", data=tips)\n",
        "plt.title(\"Linear Regression Plot\")\n",
        "plt.show()\n",
        "\n",
        "# Time Series – Heatmap (FIXED)\n",
        "flights_pivot = flights.pivot(index=\"month\", columns=\"year\", values=\"passengers\")\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(flights_pivot, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "plt.title(\"Time Series Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# QQ Plot\n",
        "plt.figure(figsize=(6,6))\n",
        "stats.probplot(iris['sepal_length'], dist=\"norm\", plot=plt)\n",
        "plt.title(\"QQ Plot\")\n",
        "plt.show()\n",
        "\n",
        "# Parallel Coordinates\n",
        "plt.figure(figsize=(10, 6))\n",
        "parallel_coordinates(iris, class_column='species', colormap='viridis')\n",
        "plt.title(\"Parallel Coordinates\")\n",
        "plt.show()\n",
        "\n",
        "# Altair Visualization\n",
        "alt.data_transformers.disable_max_rows()\n",
        "alt.Chart(tips).mark_bar().encode(\n",
        "    x='day',\n",
        "    y='mean(tip)',\n",
        "    color='sex'\n",
        ").properties(title='Altair: Mean Tip per Day by Sex')\n",
        "\n",
        "# Plotly Express\n",
        "fig = px.scatter(tips, x=\"total_bill\", y=\"tip\", color=\"sex\", size=\"size\", hover_data=['day'])\n",
        "fig.update_layout(title=\"Plotly: Total Bill vs Tip\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install joypy"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TzHTf4UsJUD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries (add if not imported already)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import joypy\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "# Dataset (using Tips for variety)\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "\n",
        "# 1. ECDF Plot (Empirical Cumulative Distribution Function)\n",
        "sns.ecdfplot(tips[\"total_bill\"])\n",
        "plt.title(\"ECDF Plot: Total Bill\")\n",
        "plt.xlabel(\"Total Bill\")\n",
        "plt.ylabel(\"ECDF\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Ridge Plot / Joyplot (Distribution by category)\n",
        "plt.figure(figsize=(10, 6))\n",
        "joypy.joyplot(tips, by=\"day\", column=\"total_bill\", colormap=plt.cm.viridis)\n",
        "plt.title(\"Ridge Plot: Total Bill Distribution by Day\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Dumbbell Plot (Difference between two groups)\n",
        "grouped = tips.groupby(\"sex\")[\"total_bill\"].agg([\"mean\", \"median\"]).T\n",
        "plt.plot(grouped.columns, grouped.loc[\"mean\"], marker=\"o\", label=\"Mean\")\n",
        "plt.plot(grouped.columns, grouped.loc[\"median\"], marker=\"o\", label=\"Median\")\n",
        "for x in grouped.columns:\n",
        "    plt.plot([x, x], grouped.loc[:, x], color=\"gray\", linestyle=\"--\")\n",
        "plt.title(\"Dumbbell Plot: Mean vs Median Total Bill by Sex\")\n",
        "plt.ylabel(\"Amount\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 4. PCA Biplot (Dimensionality reduction with interpretation)\n",
        "iris = sns.load_dataset(\"iris\")\n",
        "X = iris.select_dtypes(include=\"number\")\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "pca = PCA(n_components=2)\n",
        "pca_components = pca.fit_transform(X_scaled)\n",
        "pca_df = pd.DataFrame(pca_components, columns=[\"PC1\", \"PC2\"])\n",
        "pca_df[\"species\"] = iris[\"species\"]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"species\")\n",
        "plt.title(\"PCA Biplot: Iris Dataset\")\n",
        "plt.show()\n",
        "\n",
        "# 5. Funnel Chart (using matplotlib bar)\n",
        "stages = ['Visited', 'Subscribed', 'Converted']\n",
        "values = [1000, 600, 250]\n",
        "plt.figure(figsize=(6,4))\n",
        "for i, (stage, value) in enumerate(zip(stages, values)):\n",
        "    plt.barh(i, value, height=0.6, color='skyblue')\n",
        "    plt.text(value + 10, i, str(value), va='center')\n",
        "plt.yticks(range(len(stages)), stages)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(\"Funnel Chart Example\")\n",
        "plt.xlabel(\"Users\")\n",
        "plt.show()\n",
        "\n",
        "# 6. Bubble Plot\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=tips, x=\"total_bill\", y=\"tip\", size=\"size\", hue=\"time\", alpha=0.6, sizes=(20, 200))\n",
        "plt.title(\"Bubble Plot: Tip vs Total Bill (Size & Time Encoded)\")\n",
        "plt.show()\n",
        "\n",
        "# 7. Lorenz Curve (Income Distribution Inequality)\n",
        "income = np.sort(tips[\"total_bill\"].values)\n",
        "cum_income = np.cumsum(income) / income.sum()\n",
        "cum_population = np.arange(1, len(income)+1) / len(income)\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(cum_population, cum_income, label=\"Lorenz Curve\")\n",
        "plt.plot([0,1], [0,1], linestyle='--', color='black', label=\"Equality Line\")\n",
        "plt.title(\"Lorenz Curve: Total Bill\")\n",
        "plt.xlabel(\"Cumulative Share of People\")\n",
        "plt.ylabel(\"Cumulative Share of Total Bill\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vhqOTsf5IDD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pywaffle"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G4Gzr6cVInlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pywaffle import Waffle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sample datasets\n",
        "titanic = sns.load_dataset(\"titanic\")\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "\n",
        "# 1. Waffle Chart – Titanic Class Breakdown\n",
        "data = titanic['class'].value_counts().to_dict()\n",
        "fig = plt.figure(\n",
        "    FigureClass=Waffle,\n",
        "    rows=5,\n",
        "    values=data,\n",
        "    title={'label': 'Titanic Passengers by Class', 'loc': 'center'},\n",
        "    labels=[f\"{k} ({v})\" for k, v in data.items()],\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1)},\n",
        "    figsize=(10, 5)\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# 2. Waffle Chart – Survival Breakdown\n",
        "data = titanic['survived'].value_counts().sort_index()\n",
        "survival_labels = {0: 'Died', 1: 'Survived'}\n",
        "data.index = data.index.map(survival_labels)\n",
        "fig = plt.figure(\n",
        "    FigureClass=Waffle,\n",
        "    rows=5,\n",
        "    values=data.to_dict(),\n",
        "    title={'label': 'Titanic Survival Rate', 'loc': 'center'},\n",
        "    labels=[f\"{k} ({v})\" for k, v in data.to_dict().items()],\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1)},\n",
        "    figsize=(10, 5),\n",
        "    colors=[\"#FF9999\", \"#99FF99\"]\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# 3. Waffle Chart – Tips by Smoking Status\n",
        "data = tips[\"smoker\"].value_counts().to_dict()\n",
        "fig = plt.figure(\n",
        "    FigureClass=Waffle,\n",
        "    rows=5,\n",
        "    values=data,\n",
        "    title={'label': 'Customers by Smoking Status', 'loc': 'center'},\n",
        "    labels=[f\"{k} ({v})\" for k, v in data.items()],\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1)},\n",
        "    colors=[\"#FAD02C\", \"#2A9D8F\"],\n",
        "    figsize=(10, 5)\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# 4. Waffle Chart – Passengers by Gender\n",
        "data = titanic[\"sex\"].value_counts().to_dict()\n",
        "fig = plt.figure(\n",
        "    FigureClass=Waffle,\n",
        "    rows=5,\n",
        "    values=data,\n",
        "    title={'label': 'Titanic Passengers by Gender', 'loc': 'center'},\n",
        "    labels=[f\"{k} ({v})\" for k, v in data.items()],\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1)},\n",
        "    colors=[\"#0096C7\", \"#FF70A6\"],\n",
        "    figsize=(10, 5)\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# 5. Waffle Chart – Tips by Time of Day\n",
        "data = tips[\"time\"].value_counts().to_dict()\n",
        "fig = plt.figure(\n",
        "    FigureClass=Waffle,\n",
        "    rows=5,\n",
        "    values=data,\n",
        "    title={'label': 'Meals by Time of Day', 'loc': 'center'},\n",
        "    labels=[f\"{k} ({v})\" for k, v in data.items()],\n",
        "    legend={'loc': 'upper left', 'bbox_to_anchor': (1, 1)},\n",
        "    colors=[\"#606C38\", \"#283618\"],\n",
        "    figsize=(10, 5)\n",
        ")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "q74PviqQJrZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "from statsmodels.stats.weightstats import ztest, ttest_ind\n",
        "from statsmodels.stats.anova import anova_lm\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Load dataset\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "\n",
        "# 1. One-sample T-test (Is average tip > 2.5?)\n",
        "sample_data = tips[\"tip\"]\n",
        "t_stat, p_val = stats.ttest_1samp(sample_data, popmean=2.5)\n",
        "sns.histplot(sample_data, kde=True)\n",
        "plt.axvline(2.5, color=\"red\", linestyle=\"--\", label=\"Hypothesized Mean (2.5)\")\n",
        "plt.title(f\"One-sample T-test: t={t_stat:.2f}, p={p_val:.3f}\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 2. Independent Two-sample T-test (tips by gender)\n",
        "male = tips[tips[\"sex\"] == \"Male\"][\"tip\"]\n",
        "female = tips[tips[\"sex\"] == \"Female\"][\"tip\"]\n",
        "t_stat, p_val = stats.ttest_ind(male, female)\n",
        "sns.kdeplot(male, label=\"Male\")\n",
        "sns.kdeplot(female, label=\"Female\")\n",
        "plt.title(f\"Two-sample T-test: t={t_stat:.2f}, p={p_val:.3f}\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 3. Paired T-test (simulated before/after weight loss)\n",
        "np.random.seed(0)\n",
        "before = np.random.normal(80, 5, 30)\n",
        "after = before - np.random.normal(3, 1, 30)\n",
        "t_stat, p_val = stats.ttest_rel(before, after)\n",
        "plt.plot(before, label=\"Before\")\n",
        "plt.plot(after, label=\"After\")\n",
        "plt.title(f\"Paired T-test: t={t_stat:.2f}, p={p_val:.3f}\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 4. Z-test (Mean tip by gender)\n",
        "z_stat, p_val = ztest(male, female)\n",
        "sns.boxplot(data=tips, x=\"sex\", y=\"tip\")\n",
        "plt.title(f\"Z-test for Mean Tip: z={z_stat:.2f}, p={p_val:.3f}\")\n",
        "plt.show()\n",
        "\n",
        "# 5. One-way ANOVA (tip ~ day)\n",
        "model = ols('tip ~ C(day)', data=tips).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "sns.boxplot(data=tips, x=\"day\", y=\"tip\")\n",
        "plt.title(f\"One-way ANOVA: p={anova_table['PR(>F)'][0]:.4f}\")\n",
        "plt.show()\n",
        "\n",
        "# 6. Post-Hoc: Tukey HSD if ANOVA is significant\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "tukey = pairwise_tukeyhsd(endog=tips['tip'], groups=tips['day'], alpha=0.05)\n",
        "print(tukey)\n",
        "\n",
        "# 7. Chi-square Test of Independence (sex vs smoker)\n",
        "contingency = pd.crosstab(tips[\"sex\"], tips[\"smoker\"])\n",
        "chi2, p, dof, expected = chi2_contingency(contingency)\n",
        "sns.heatmap(contingency, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(f\"Chi-square Test: χ²={chi2:.2f}, p={p:.3f}\")\n",
        "plt.show()\n",
        "\n",
        "# 8. Normality Check – QQ Plot\n",
        "sm.qqplot(tips[\"tip\"], line=\"s\")\n",
        "plt.title(\"QQ Plot: Normality Check for Tip\")\n",
        "plt.show()\n",
        "\n",
        "# 9. Homogeneity of Variance – Levene's Test\n",
        "stat, p = stats.levene(\n",
        "    tips[tips[\"day\"] == \"Sun\"][\"tip\"],\n",
        "    tips[tips[\"day\"] == \"Sat\"][\"tip\"]\n",
        ")\n",
        "sns.boxplot(data=tips[tips[\"day\"].isin([\"Sun\", \"Sat\"])], x=\"day\", y=\"tip\")\n",
        "plt.title(f\"Levene's Test (Equal Variance): p={p:.3f}\")\n",
        "plt.show()\n",
        "\n",
        "# 10. Residual Plot (ANOVA diagnostics)\n",
        "residuals = model.resid\n",
        "fitted = model.fittedvalues\n",
        "sns.residplot(x=fitted, y=residuals, lowess=True)\n",
        "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "plt.title(\"Residuals vs Fitted (ANOVA Diagnostics)\")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9fglq1KtJ_qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import mean_squared_error, confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Simulate data\n",
        "np.random.seed(42)\n",
        "X = np.linspace(0, 10, 100)\n",
        "y = 3 * X + np.random.normal(0, 3, size=X.shape)\n",
        "\n",
        "X = X.reshape(-1, 1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# 1. Compare Linear, Ridge, and Lasso Regression\n",
        "models = {\n",
        "    \"Linear\": LinearRegression(),\n",
        "    \"Ridge (α=1)\": Ridge(alpha=1),\n",
        "    \"Lasso (α=0.1)\": Lasso(alpha=0.1)\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(X_train, y_train, label=\"Train\", alpha=0.5)\n",
        "plt.scatter(X_test, y_test, label=\"Test\", alpha=0.5)\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    plt.plot(X_test, y_pred, label=f\"{name} (MSE={mean_squared_error(y_test, y_pred):.2f})\")\n",
        "\n",
        "plt.title(\"Linear vs Ridge vs Lasso Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 2. Compare Linear vs Polynomial Regression\n",
        "poly_model = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())\n",
        "poly_model.fit(X_train, y_train)\n",
        "y_pred_poly = poly_model.predict(X_test)\n",
        "\n",
        "lin_model = LinearRegression().fit(X_train, y_train)\n",
        "y_pred_lin = lin_model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(X, y, alpha=0.4, label=\"Data\")\n",
        "plt.plot(X_test, y_pred_lin, label=\"Linear Regression\", color=\"red\")\n",
        "plt.plot(X_test, y_pred_poly, label=\"Polynomial (deg=3)\", color=\"green\")\n",
        "plt.title(\"Linear vs Polynomial Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 3. Classification: Logistic Regression on Titanic\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "titanic = sns.load_dataset(\"titanic\").dropna(subset=[\"sex\", \"age\", \"fare\", \"survived\"])\n",
        "titanic[\"sex_binary\"] = (titanic[\"sex\"] == \"male\").astype(int)\n",
        "\n",
        "X = titanic[[\"age\", \"fare\", \"sex_binary\"]]\n",
        "y = titanic[\"survived\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "y_proba = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Confusion Matrix\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
        "plt.title(\"Logistic Regression – Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
        "plt.plot([0,1], [0,1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve – Logistic Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 4. Overfitting vs Underfitting (Simulation)\n",
        "X = np.linspace(0, 6, 100)\n",
        "y_true = np.sin(X) + np.random.normal(0, 0.2, size=X.shape)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "for i, deg in enumerate([1, 4, 15]):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    model = make_pipeline(PolynomialFeatures(degree=deg), LinearRegression())\n",
        "    model.fit(X.reshape(-1,1), y_true)\n",
        "    y_pred = model.predict(X.reshape(-1,1))\n",
        "    plt.plot(X, y_true, label=\"True\", color=\"gray\", alpha=0.5)\n",
        "    plt.plot(X, y_pred, label=f\"Degree {deg}\")\n",
        "    plt.title(f\"Poly Degree {deg}\")\n",
        "    plt.ylim(-2, 2)\n",
        "    plt.legend()\n",
        "\n",
        "plt.suptitle(\"Underfitting vs Overfitting\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5m95qsIMKam1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Titanic binary classifier (Male vs Female survival)\n",
        "titanic = sns.load_dataset(\"titanic\").dropna(subset=[\"sex\", \"age\", \"fare\", \"survived\"])\n",
        "titanic[\"sex_binary\"] = (titanic[\"sex\"] == \"male\").astype(int)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = titanic[[\"age\", \"fare\", \"sex_binary\"]]\n",
        "y = titanic[\"survived\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# Calculate metrics manually\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Create DataFrame for comparison\n",
        "metrics_df = pd.DataFrame({\n",
        "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall (Sensitivity)\", \"Specificity\", \"F1 Score\"],\n",
        "    \"Value\": [accuracy, precision, recall, specificity, f1]\n",
        "})\n",
        "\n",
        "# Barplot\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(data=metrics_df, x=\"Metric\", y=\"Value\", palette=\"viridis\")\n",
        "plt.ylim(0, 1)\n",
        "plt.title(\"Comparison of Classification Metrics\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.grid(True, axis='y', linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# Print numerical values\n",
        "print(metrics_df.to_string(index=False))\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate (Recall)\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q9C6gfsaKr-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "import seaborn as sns\n",
        "\n",
        "# Set seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create a skewed population (exponential distribution)\n",
        "population = np.random.exponential(scale=2, size=100000)\n",
        "\n",
        "# Parameters\n",
        "sample_size = 50\n",
        "num_iterations = 100\n",
        "sample_means = []\n",
        "\n",
        "# Set up the plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.set_style(\"whitegrid\")\n",
        "bars = None\n",
        "\n",
        "def update(frame):\n",
        "    global sample_means, bars\n",
        "    sample = np.random.choice(population, size=sample_size, replace=False)\n",
        "    sample_means.append(np.mean(sample))\n",
        "    ax.clear()\n",
        "\n",
        "    # Histogram of sample means\n",
        "    sns.histplot(sample_means, kde=True, stat=\"density\", bins=20, color='skyblue', ax=ax)\n",
        "    ax.set_xlim(0, 6)\n",
        "    ax.set_ylim(0, 2)\n",
        "    ax.set_title(f\"Central Limit Theorem Simulation\\nIteration {frame+1} — Sample size: {sample_size}\")\n",
        "    ax.set_xlabel(\"Sample Means\")\n",
        "    ax.set_ylabel(\"Density\")\n",
        "\n",
        "ani = animation.FuncAnimation(fig, update, frames=num_iterations, repeat=False, interval=200)\n",
        "plt.close()  # Prevent static plot in Colab\n",
        "\n",
        "# To display in Colab:\n",
        "from IPython.display import HTML\n",
        "HTML(ani.to_jshtml())\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6rHZjid_LD6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ipywidgets scikit-learn seaborn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Load & prep Titanic data\n",
        "titanic = sns.load_dataset(\"titanic\").dropna(subset=[\"age\", \"fare\", \"sex\", \"survived\"])\n",
        "titanic[\"sex_binary\"] = (titanic[\"sex\"] == \"male\").astype(int)\n",
        "\n",
        "X = titanic[[\"age\", \"fare\", \"sex_binary\"]]\n",
        "y = titanic[\"survived\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Fit logistic regression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ROC curve data\n",
        "fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# INTERACTIVE DISPLAY FUNCTION\n",
        "def update_threshold(thresh):\n",
        "    preds = (probs >= thresh).astype(int)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    precision = precision_score(y_test, preds)\n",
        "    recall = recall_score(y_test, preds)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # ROC curve\n",
        "    axs[0].plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
        "    axs[0].axvline((preds != y_test).mean(), color='red', linestyle='--', label=f\"Threshold = {thresh:.2f}\")\n",
        "    axs[0].plot([0, 1], [0, 1], 'k--')\n",
        "    axs[0].set_xlabel(\"False Positive Rate\")\n",
        "    axs[0].set_ylabel(\"True Positive Rate (Recall)\")\n",
        "    axs[0].set_title(\"ROC Curve\")\n",
        "    axs[0].legend()\n",
        "\n",
        "    # Confusion Matrix as heatmap\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axs[1], cbar=False)\n",
        "    axs[1].set_title(f\"Confusion Matrix @ Threshold {thresh:.2f}\")\n",
        "    axs[1].set_xlabel(\"Predicted\")\n",
        "    axs[1].set_ylabel(\"Actual\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Precision: {precision:.2f} | Recall: {recall:.2f}\")\n",
        "\n",
        "# Interactive slider\n",
        "threshold_slider = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.01, description='Threshold:')\n",
        "widgets.interact(update_threshold, thresh=threshold_slider)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4NlLNOZRLf9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pywaffle"
      ],
      "metadata": {
        "id": "AmRVYTTuLvhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "\n",
        "# Build a regression model\n",
        "X = tips[[\"total_bill\", \"size\"]]\n",
        "X = sm.add_constant(X)\n",
        "y = tips[\"tip\"]\n",
        "\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# 1. Influence Plot (Leverage vs Studentized Residuals)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sm.graphics.influence_plot(model, ax=ax, criterion=\"cooks\")\n",
        "plt.title(\"Influence Plot: Leverage vs Studentized Residuals\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Leverage vs Squared Residuals\n",
        "influence = model.get_influence()\n",
        "leverage = influence.hat_matrix_diag\n",
        "resid_student = influence.resid_studentized_internal\n",
        "cook = influence.cooks_distance[0]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=leverage, y=resid_student**2, size=cook, sizes=(20, 300), alpha=0.6)\n",
        "plt.xlabel(\"Leverage\")\n",
        "plt.ylabel(\"Studentized Residual²\")\n",
        "plt.title(\"Leverage vs Studentized Residuals Squared\\n(Bubble size = Cook's Distance)\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# 3. Cook's Distance Bar Plot\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.stem(cook, basefmt=\" \")\n",
        "plt.axhline(4 / len(X), color=\"red\", linestyle=\"--\", label=\"Threshold (4/n)\")\n",
        "plt.title(\"Cook's Distance for All Observations\")\n",
        "plt.xlabel(\"Observation Index\")\n",
        "plt.ylabel(\"Cook's Distance\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "m55K4mDgMHQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q umap-learn\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import umap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Scale data before reduction\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# t-SNE\n",
        "tsne = TSNE(n_components=2, perplexity=30, learning_rate='auto', init='pca', random_state=42)\n",
        "X_tsne = tsne.fit_transform(X_scaled)\n",
        "\n",
        "# UMAP\n",
        "reducer = umap.UMAP(n_components=2, random_state=42)\n",
        "X_umap = reducer.fit_transform(X_scaled)\n",
        "\n",
        "# Convert to DataFrame for plotting\n",
        "df_tsne = pd.DataFrame(X_tsne, columns=[\"Dim1\", \"Dim2\"])\n",
        "df_tsne[\"target\"] = y\n",
        "df_tsne[\"method\"] = \"t-SNE\"\n",
        "\n",
        "df_umap = pd.DataFrame(X_umap, columns=[\"Dim1\", \"Dim2\"])\n",
        "df_umap[\"target\"] = y\n",
        "df_umap[\"method\"] = \"UMAP\"\n",
        "\n",
        "# Combine\n",
        "df_vis = pd.concat([df_tsne, df_umap])\n",
        "\n",
        "# Plot both\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(data=df_vis, x=\"Dim1\", y=\"Dim2\", hue=\"target\", style=\"method\", palette=\"Set1\")\n",
        "plt.title(\"t-SNE vs UMAP on Iris Dataset\")\n",
        "plt.legend(title=\"Target / Method\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7uQdfLjWMT4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "tips = sns.load_dataset(\"tips\")\n",
        "\n",
        "# Bootstrap Parameters\n",
        "np.random.seed(42)\n",
        "n_iterations = 5000\n",
        "statistic = np.mean  # You can switch to np.median, np.std, etc.\n",
        "sample_size = len(tips[\"tip\"])\n",
        "\n",
        "# Collect bootstrap samples\n",
        "bootstrap_estimates = []\n",
        "for _ in range(n_iterations):\n",
        "    sample = tips[\"tip\"].sample(n=sample_size, replace=True)\n",
        "    stat = statistic(sample)\n",
        "    bootstrap_estimates.append(stat)\n",
        "\n",
        "# Convert to array\n",
        "bootstrap_estimates = np.array(bootstrap_estimates)\n",
        "\n",
        "# Confidence Interval (e.g., 95%)\n",
        "lower = np.percentile(bootstrap_estimates, 2.5)\n",
        "upper = np.percentile(bootstrap_estimates, 97.5)\n",
        "original_stat = statistic(tips[\"tip\"])\n",
        "\n",
        "# Plot KDE of bootstrapped estimates\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(bootstrap_estimates, fill=True, color='skyblue', label=\"Bootstrap Distribution\")\n",
        "plt.axvline(original_stat, color='blue', linestyle='--', label=f\"Original Mean: {original_stat:.2f}\")\n",
        "plt.axvline(lower, color='red', linestyle='--', label=f\"2.5% CI: {lower:.2f}\")\n",
        "plt.axvline(upper, color='red', linestyle='--', label=f\"97.5% CI: {upper:.2f}\")\n",
        "plt.title(\"Bootstrap Confidence Interval for Tip Mean\")\n",
        "plt.xlabel(\"Bootstrapped Mean Tip\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MARbnsiqMp0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load a real-world dataset (California Housing)\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# Fit model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Choose features for ICE (can be any continuous variable)\n",
        "features = [\"MedInc\", \"AveRooms\", \"HouseAge\"]\n",
        "\n",
        "# Plot ICE\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "PartialDependenceDisplay.from_estimator(\n",
        "    model, X_test, features, kind=\"individual\", subsample=50, grid_resolution=50, ax=ax\n",
        ")\n",
        "plt.suptitle(\"ICE Plots: How Features Affect Predictions (California Housing)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fCYvESRFMxlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Generate or load dataset\n",
        "# You can replace this with titanic or any binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=5, n_informative=3, random_state=42)\n",
        "X = pd.DataFrame(X, columns=[f\"f{i}\" for i in range(5)])\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Create DataFrame for gains/lift\n",
        "results = pd.DataFrame({\"y_true\": y_test, \"y_proba\": y_proba})\n",
        "results = results.sort_values(\"y_proba\", ascending=False).reset_index(drop=True)\n",
        "results[\"decile\"] = pd.qcut(results.index, 10, labels=False)\n",
        "\n",
        "# Gains calculation\n",
        "gains = results.groupby(\"decile\").agg({\"y_true\": [\"sum\", \"count\"]})\n",
        "gains.columns = [\"positives\", \"count\"]\n",
        "gains[\"cum_positives\"] = gains[\"positives\"].cumsum()\n",
        "gains[\"cum_pct_positives\"] = gains[\"cum_positives\"] / gains[\"positives\"].sum()\n",
        "gains[\"data_pct\"] = (np.arange(1, 11)) / 10\n",
        "\n",
        "# Lift calculation\n",
        "gains[\"lift\"] = gains[\"cum_pct_positives\"] / gains[\"data_pct\"]\n",
        "\n",
        "# Plot Gains Chart\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(gains[\"data_pct\"], gains[\"cum_pct_positives\"], marker=\"o\", label=\"Model\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random\")\n",
        "plt.title(\"Gains Chart\")\n",
        "plt.xlabel(\"Proportion of Data (Top % Ranked)\")\n",
        "plt.ylabel(\"Cumulative % of Positives Captured\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# Plot Lift Chart\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(gains[\"data_pct\"], gains[\"lift\"], marker=\"o\", color=\"purple\")\n",
        "plt.axhline(1, linestyle=\"--\", color=\"gray\", label=\"Baseline Lift = 1\")\n",
        "plt.title(\"Lift Chart\")\n",
        "plt.xlabel(\"Proportion of Data (Top % Ranked)\")\n",
        "plt.ylabel(\"Lift\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qoZ-cpXWNIls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load Titanic dataset\n",
        "titanic = sns.load_dataset(\"titanic\").dropna(subset=[\"sex\", \"age\", \"fare\", \"survived\"])\n",
        "titanic[\"sex_binary\"] = (titanic[\"sex\"] == \"male\").astype(int)\n",
        "\n",
        "# Feature and target\n",
        "X = titanic[[\"age\", \"fare\", \"sex_binary\"]]\n",
        "y = titanic[\"survived\"]\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Create DataFrame for gains/lift calculation\n",
        "results = pd.DataFrame({\"y_true\": y_test, \"y_proba\": y_proba})\n",
        "results = results.sort_values(\"y_proba\", ascending=False).reset_index(drop=True)\n",
        "results[\"decile\"] = pd.qcut(results.index, 10, labels=False)\n",
        "\n",
        "# Compute gains\n",
        "gains = results.groupby(\"decile\").agg({\"y_true\": [\"sum\", \"count\"]})\n",
        "gains.columns = [\"positives\", \"count\"]\n",
        "gains[\"cum_positives\"] = gains[\"positives\"].cumsum()\n",
        "gains[\"cum_pct_positives\"] = gains[\"cum_positives\"] / gains[\"positives\"].sum()\n",
        "gains[\"data_pct\"] = (np.arange(1, 11)) / 10\n",
        "\n",
        "# Compute lift\n",
        "gains[\"lift\"] = gains[\"cum_pct_positives\"] / gains[\"data_pct\"]\n",
        "\n",
        "# Plot Gains Chart\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(gains[\"data_pct\"], gains[\"cum_pct_positives\"], marker=\"o\", label=\"Model\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random\")\n",
        "plt.title(\"Gains Chart – Titanic Survival Model\")\n",
        "plt.xlabel(\"Proportion of Data (Top % Ranked)\")\n",
        "plt.ylabel(\"Cumulative % of Survivors Captured\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "# Plot Lift Chart\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(gains[\"data_pct\"], gains[\"lift\"], marker=\"o\", color=\"purple\")\n",
        "plt.axhline(1, linestyle=\"--\", color=\"gray\", label=\"Baseline Lift = 1\")\n",
        "plt.title(\"Lift Chart – Titanic Survival Model\")\n",
        "plt.xlabel(\"Proportion of Data (Top % Ranked)\")\n",
        "plt.ylabel(\"Lift Over Random\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oFXxHSLCNYpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Simulate batch data for drift detection (based on Titanic dataset)\n",
        "titanic = sns.load_dataset(\"titanic\").dropna(subset=[\"sex\", \"age\", \"fare\", \"survived\"])\n",
        "titanic[\"sex_binary\"] = (titanic[\"sex\"] == \"male\").astype(int)\n",
        "\n",
        "X = titanic[[\"age\", \"fare\", \"sex_binary\"]]\n",
        "y = titanic[\"survived\"]\n",
        "\n",
        "# Shuffle and simulate 10 time-based batches\n",
        "n_batches = 10\n",
        "titanic[\"batch\"] = np.tile(np.arange(n_batches), len(titanic) // n_batches + 1)[:len(titanic)]\n",
        "\n",
        "# Fit on initial batch (simulate training in production)\n",
        "train_data = titanic[titanic[\"batch\"] == 0]\n",
        "X_train = train_data[[\"age\", \"fare\", \"sex_binary\"]]\n",
        "y_train = train_data[\"survived\"]\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on batches 1–9 to simulate monitoring\n",
        "metrics = []\n",
        "\n",
        "for batch in range(1, n_batches):\n",
        "    test_data = titanic[titanic[\"batch\"] == batch]\n",
        "    X_test = test_data[[\"age\", \"fare\", \"sex_binary\"]]\n",
        "    y_test = test_data[\"survived\"]\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    metrics.append({\n",
        "        \"batch\": batch,\n",
        "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
        "        \"auc\": roc_auc_score(y_test, y_proba)\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "\n",
        "# Plot the metrics over batches\n",
        "plt.figure(figsize=(12, 6))\n",
        "for col in [\"accuracy\", \"precision\", \"recall\", \"f1\", \"auc\"]:\n",
        "    sns.lineplot(x=\"batch\", y=col, data=metrics_df, label=col, marker=\"o\")\n",
        "\n",
        "plt.title(\"Model Drift Visualization Over Time (Titanic Example)\")\n",
        "plt.xlabel(\"Batch (Simulated Time)\")\n",
        "plt.ylabel(\"Metric Score\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "g0jKDbhHNooU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_curve, precision_recall_curve, confusion_matrix, f1_score, roc_auc_score\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load Titanic data\n",
        "titanic = sns.load_dataset(\"titanic\").dropna(subset=[\"sex\", \"age\", \"fare\", \"survived\"])\n",
        "titanic[\"sex_binary\"] = (titanic[\"sex\"] == \"male\").astype(int)\n",
        "\n",
        "X = titanic[[\"age\", \"fare\", \"sex_binary\"]]\n",
        "y = titanic[\"survived\"]\n",
        "\n",
        "# Split and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_proba = model.predict_proba(X_test)[:, 1]\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "fpr, tpr, roc_thresholds = roc_curve(y_test, y_proba)\n",
        "prec, rec, pr_thresholds = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "f1_scores = [f1_score(y_test, y_proba >= t) for t in thresholds]\n",
        "\n",
        "# Lift Curve\n",
        "df_lift = pd.DataFrame({'y_true': y_test, 'y_proba': y_proba})\n",
        "df_lift = df_lift.sort_values(\"y_proba\", ascending=False)\n",
        "df_lift[\"decile\"] = pd.qcut(df_lift.index, 10, labels=False)\n",
        "\n",
        "lift = df_lift.groupby(\"decile\").agg({\"y_true\": [\"sum\", \"count\"]})\n",
        "lift.columns = [\"positives\", \"total\"]\n",
        "lift[\"cum_positives\"] = lift[\"positives\"].cumsum()\n",
        "lift[\"cum_rate\"] = lift[\"cum_positives\"] / lift[\"positives\"].sum()\n",
        "lift[\"baseline\"] = np.linspace(0.1, 1.0, 10)\n",
        "lift[\"lift\"] = lift[\"cum_rate\"] / lift[\"baseline\"]\n",
        "\n",
        "# Grid Plot\n",
        "fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# ROC\n",
        "axs[0, 0].plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_proba):.2f}\")\n",
        "axs[0, 0].plot([0, 1], [0, 1], 'k--')\n",
        "axs[0, 0].set_title(\"ROC Curve\")\n",
        "axs[0, 0].set_xlabel(\"False Positive Rate\")\n",
        "axs[0, 0].set_ylabel(\"True Positive Rate\")\n",
        "axs[0, 0].legend()\n",
        "\n",
        "# Precision-Recall\n",
        "axs[0, 1].plot(rec, prec)\n",
        "axs[0, 1].set_title(\"Precision-Recall Curve\")\n",
        "axs[0, 1].set_xlabel(\"Recall\")\n",
        "axs[0, 1].set_ylabel(\"Precision\")\n",
        "\n",
        "# F1 vs Threshold\n",
        "axs[0, 2].plot(thresholds, f1_scores, color='purple')\n",
        "axs[0, 2].set_title(\"F1 Score vs Threshold\")\n",
        "axs[0, 2].set_xlabel(\"Threshold\")\n",
        "axs[0, 2].set_ylabel(\"F1 Score\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=axs[1, 0])\n",
        "axs[1, 0].set_title(\"Confusion Matrix\")\n",
        "axs[1, 0].set_xlabel(\"Predicted\")\n",
        "axs[1, 0].set_ylabel(\"Actual\")\n",
        "\n",
        "# Lift Chart\n",
        "axs[1, 1].plot(lift[\"baseline\"], lift[\"lift\"], marker=\"o\", color='green')\n",
        "axs[1, 1].axhline(1, linestyle=\"--\", color=\"gray\")\n",
        "axs[1, 1].set_title(\"Lift Curve\")\n",
        "axs[1, 1].set_xlabel(\"Cumulative % of Data\")\n",
        "axs[1, 1].set_ylabel(\"Lift Over Baseline\")\n",
        "\n",
        "# Empty / Optional Extra Space\n",
        "axs[1, 2].axis('off')\n",
        "axs[1, 2].text(0.5, 0.5, \"← Add SHAP, Calibration, or LogLoss\\nin this panel\",\n",
        "              ha=\"center\", va=\"center\", fontsize=12, color='gray')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "R0AL_nk6Nxxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import entropy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load Titanic dataset\n",
        "titanic = sns.load_dataset(\"titanic\").copy()\n",
        "\n",
        "# Drop ID-like columns and clean\n",
        "df = titanic.drop(columns=[\"embark_town\", \"alive\", \"deck\"])\n",
        "df = df.dropna(axis=1, how=\"any\")\n",
        "df = df.select_dtypes(include=[\"number\", \"category\", \"object\"])\n",
        "\n",
        "# Encode categorical features temporarily\n",
        "encoded_df = df.copy()\n",
        "label_encoders = {}\n",
        "\n",
        "for col in encoded_df.select_dtypes(include=[\"object\", \"category\"]).columns:\n",
        "    le = LabelEncoder()\n",
        "    encoded_df[col] = le.fit_transform(encoded_df[col].astype(str))\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# ---------- DISTRIBUTION HEATMAP ----------\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(encoded_df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------- ENTROPY FINGERPRINT ----------\n",
        "def compute_entropy(col):\n",
        "    counts = col.value_counts()\n",
        "    return entropy(counts, base=2)\n",
        "\n",
        "entropies = encoded_df.apply(compute_entropy)\n",
        "entropies = entropies.sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.barplot(x=entropies.values, y=entropies.index, palette=\"viridis\")\n",
        "plt.title(\"Entropy Fingerprint (Information Richness by Feature)\")\n",
        "plt.xlabel(\"Entropy (bits)\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.grid(True, axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------- HISTOGRAM FINGERPRINT ----------\n",
        "numeric_cols = encoded_df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "\n",
        "n_cols = 3\n",
        "n_rows = int(np.ceil(len(numeric_cols) / n_cols))\n",
        "\n",
        "fig, axs = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 3))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    sns.histplot(encoded_df[col], kde=True, ax=axs[i], color='steelblue')\n",
        "    axs[i].set_title(f\"Histogram: {col}\")\n",
        "    axs[i].grid(True, linestyle=\"--\", alpha=0.4)\n",
        "\n",
        "# Turn off unused axes\n",
        "for j in range(i+1, len(axs)):\n",
        "    axs[j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nK-bPLDBN1NO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}