{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Probability, Likelihood, and Probability Distributions: A Conceptual Clarification\n",
        "\n",
        "Probability, likelihood, and probability distributions are closely related mathematical objects, but they play fundamentally different roles in statistical reasoning.  \n",
        "The key distinction between them lies **not in the formula itself**—often the same expression appears in all three—but in **which quantities are treated as known, which are unknown, and what inference task is being performed**.\n",
        "\n",
        "At a high level:\n",
        "\n",
        "- **Probability** is about **prediction**:  \n",
        "  *What outcomes should we expect if the model is already known?*\n",
        "\n",
        "- **Likelihood** is about **inference**:  \n",
        "  *Which model parameters best explain the data we have observed?*\n",
        "\n",
        "- **Probability distributions** are **models**:  \n",
        "  They describe the entire space of possible outcomes and how probability mass or density is allocated across that space.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Probability — Forward Reasoning (Prediction)\n",
        "\n",
        "**Probability answers the question:**\n",
        "\n",
        "> Given a model with known parameters, how likely is a particular outcome?\n",
        "\n",
        "Mathematically, probability is written as\n",
        "\n",
        "$$\n",
        "P(x \\mid \\theta)\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $\\theta$ represents **fixed, known model parameters**\n",
        "- $x$ represents a **random outcome**\n",
        "\n",
        "Here, randomness lies entirely in the data $x$, **not** in the parameters.\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "- Probability measures the chance or long-run frequency with which an outcome would occur if the data-generating process were repeated many times.\n",
        "- It is **normalized**:\n",
        "  - $0 \\le P(x \\mid \\theta) \\le 1$\n",
        "  - The total probability across all possible outcomes must sum (or integrate) to 1.\n",
        "\n",
        "### Example\n",
        "\n",
        "Given that a coin is fair ($\\theta = 0.5$), what is the probability of observing 5 heads in 10 tosses?\n",
        "\n",
        "This is a **predictive** question: the model is assumed correct, and we ask what data it produces.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Likelihood — Reverse Reasoning (Inference)\n",
        "\n",
        "**Likelihood answers the question:**\n",
        "\n",
        "> Given observed data, how plausible are different parameter values?\n",
        "\n",
        "Likelihood uses the *same mathematical expression* as probability, but it is interpreted differently:\n",
        "\n",
        "$$\n",
        "L(\\theta \\mid x) = P(x \\mid \\theta)\n",
        "$$\n",
        "\n",
        "The crucial difference is **conceptual**:\n",
        "\n",
        "- The data $x$ is now **fixed and observed**\n",
        "- The parameters $\\theta$ are treated as **variable and unknown**\n",
        "\n",
        "### Interpretation\n",
        "\n",
        "- Likelihood is **not** a probability of parameters.\n",
        "- It is a **relative measure of support** that the observed data provides for different parameter values.\n",
        "- Likelihoods:\n",
        "  - Do **not** need to sum to 1\n",
        "  - Can take values greater than 1\n",
        "- What matters is **comparison**, not absolute scale:\n",
        "\n",
        "> Which parameter value makes the observed data most plausible?\n",
        "\n",
        "### Example\n",
        "\n",
        "Given that we observed 5 heads in 10 tosses, how plausible is it that the coin’s bias is $0.5$ compared to $0.7$?\n",
        "\n",
        "This is an **inferential** question: the data is known, and we reason backward toward the model.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Probability Distributions — The Generative Model\n",
        "\n",
        "A **probability distribution** is a mathematical function that defines:\n",
        "\n",
        "- The set of all possible outcomes\n",
        "- The probability (or density) assigned to each outcome\n",
        "\n",
        "Formally, a distribution specifies\n",
        "\n",
        "$$\n",
        "P(x \\mid \\theta)\n",
        "$$\n",
        "\n",
        "for **all possible values** of $x$.\n",
        "\n",
        "### Role\n",
        "\n",
        "Probability distributions are the **generative mechanisms** behind both probability and likelihood.\n",
        "\n",
        "They describe how data would be generated if the parameters were known.\n",
        "\n",
        "### Examples\n",
        "\n",
        "- **Binomial distribution**: models counts of successes\n",
        "- **Normal distribution**: models continuous variation around a mean\n",
        "- **Poisson distribution**: models event counts in time or space\n",
        "\n",
        "Without a probability distribution, **neither probability nor likelihood can be defined**.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Side-by-Side Conceptual Comparison\n",
        "\n",
        "| Aspect | Probability | Likelihood |\n",
        "|------|------------|------------|\n",
        "| Fixed quantity | Parameters $\\theta$ | Observed data $x$ |\n",
        "| Variable quantity | Data $x$ | Parameters $\\theta$ |\n",
        "| Question asked | “What data should I expect?” | “Which parameters explain the data?” |\n",
        "| Purpose | Prediction | Inference |\n",
        "| Normalization | Must sum/integrate to 1 | No normalization required |\n",
        "| Typical use | Simulation, forecasting | Estimation, model fitting |\n",
        "\n",
        "---\n",
        "\n",
        "## 5. The Core Insight\n",
        "\n",
        "The most important idea to internalize is this:\n",
        "\n",
        "> **Probability and likelihood are the same function viewed from opposite directions.**\n",
        "\n",
        "- Probability looks **forward**:  \n",
        "  $$ \\text{model} \\;\\rightarrow\\; \\text{data} $$\n",
        "\n",
        "- Likelihood looks **backward**:  \n",
        "  $$ \\text{data} \\;\\rightarrow\\; \\text{model} $$\n",
        "\n",
        "Both are grounded in the same probability distribution, but they serve **entirely different epistemic purposes**.\n",
        "\n",
        "---\n",
        "\n",
        "## Final Summary\n",
        "\n",
        "- **Probability** is used when the model is known and we want to predict outcomes.\n",
        "- **Likelihood** is used when the data is known and we want to infer parameters.\n",
        "- **Probability distributions** are the underlying generative structures that make both possible.\n",
        "\n",
        "In short:\n",
        "\n",
        "- Probability predicts data.  \n",
        "- Likelihood evaluates models.  \n",
        "- Distributions define the world in which both live.\n"
      ],
      "metadata": {
        "id": "wU5uYEleIuMl"
      }
    }
  ]
}