{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Factorization of Probability  \n",
        "\n",
        "\n",
        "## 1. Why Factorization Exists at All\n",
        "\n",
        "At its core, probability becomes intractable because of combinatorial explosion.\n",
        "\n",
        "For a joint distribution:\n",
        "\n",
        "$$\n",
        "p(x_1,x_2,\\dots,x_n)\n",
        "$$\n",
        "\n",
        "If each variable has $k$ states, then the joint space contains:\n",
        "\n",
        "$$\n",
        "k^n\n",
        "$$\n",
        "\n",
        "possibilities.\n",
        "\n",
        "Storage, inference, and marginalization all become exponential.\n",
        "\n",
        "Factorization is the act of rewriting a joint probability into smaller, structured components such that:\n",
        "\n",
        "- computation becomes polynomial or linear  \n",
        "- inference becomes local  \n",
        "- learning becomes feasible  \n",
        "\n",
        "Factorization is not a modeling trick — it is a survival mechanism.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. The Fundamental Identity (Chain Rule)\n",
        "\n",
        "Everything starts here:\n",
        "\n",
        "$$\n",
        "p(x_1,\\dots,x_n)\n",
        "=\n",
        "\\prod_{i=1}^{n} p(x_i \\mid x_1,\\dots,x_{i-1})\n",
        "$$\n",
        "\n",
        "This identity is:\n",
        "\n",
        "- exact  \n",
        "- always true  \n",
        "- still intractable  \n",
        "\n",
        "Because each conditional depends on everything before it.\n",
        "\n",
        "So the real question is:\n",
        "\n",
        "How can we simplify the conditionals?\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Independence as the First Factorization\n",
        "\n",
        "### Full Independence\n",
        "\n",
        "Assume:\n",
        "\n",
        "$$\n",
        "x_i \\perp x_j \\quad \\forall\\, i \\ne j\n",
        "$$\n",
        "\n",
        "Then:\n",
        "\n",
        "$$\n",
        "p(x_1,\\dots,x_n)=\\prod_i p(x_i)\n",
        "$$\n",
        "\n",
        "Maximal simplification  \n",
        "Almost never true in reality\n",
        "\n",
        "Used in:\n",
        "\n",
        "- Naive Bayes  \n",
        "- Classical probability tables  \n",
        "- Early statistics  \n",
        "\n",
        "This is brute-force factorization.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Conditional Independence: The Real Power\n",
        "\n",
        "Instead of saying:\n",
        "\n",
        "“Nothing depends on anything”\n",
        "\n",
        "We say:\n",
        "\n",
        "“Things depend only on what matters”\n",
        "\n",
        "Formally:\n",
        "\n",
        "$$\n",
        "x_i \\perp x_j \\mid z\n",
        "$$\n",
        "\n",
        "Meaning: once $z$ is known, $x_i$ and $x_j$ do not exchange information.\n",
        "\n",
        "This allows:\n",
        "\n",
        "$$\n",
        "p(x_1,\\dots,x_n)=\\prod_i p(x_i \\mid \\mathrm{parents}(x_i))\n",
        "$$\n",
        "\n",
        "This is the birth of graphical models.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Directed Factorization (Bayesian Networks)\n",
        "\n",
        "If variables form a DAG:\n",
        "\n",
        "$$\n",
        "p(x_1,\\dots,x_n)=\\prod_i p(x_i \\mid \\mathrm{Pa}(x_i))\n",
        "$$\n",
        "\n",
        "### Key Properties\n",
        "\n",
        "- encodes causal or generative structure  \n",
        "- each factor is local  \n",
        "- global joint reconstructed exactly  \n",
        "\n",
        "### Consequences\n",
        "\n",
        "- storage: exponential → linear  \n",
        "- inference: global → message passing  \n",
        "- learning: local likelihoods  \n",
        "\n",
        "This is the most important factorization in probabilistic reasoning.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Undirected Factorization (Markov Random Fields)\n",
        "\n",
        "Instead of conditionals, we use potentials:\n",
        "\n",
        "$$\n",
        "p(x)=\\frac{1}{Z}\\prod_{c\\in C}\\psi_c(x_c)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\psi_c$: compatibility functions  \n",
        "- $Z$: partition function  \n",
        "\n",
        "This trades:\n",
        "\n",
        "- easy local structure  \n",
        "\n",
        "for:\n",
        "\n",
        "- hard global normalization  \n",
        "\n",
        "Used when:\n",
        "\n",
        "- symmetry matters  \n",
        "- no natural direction  \n",
        "- constraints dominate  \n",
        "\n",
        "---\n",
        "\n",
        "## 7. Factor Graphs: Explicit Factorization Objects\n",
        "\n",
        "Instead of variables and edges, we model:\n",
        "\n",
        "$$\n",
        "p(x)=\\prod_f f(x_f)\n",
        "$$\n",
        "\n",
        "This makes factorization:\n",
        "\n",
        "- explicit  \n",
        "- modular  \n",
        "- algorithm-friendly  \n",
        "\n",
        "Belief propagation operates directly on this structure.\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Exchangeability and Symmetry Factorization\n",
        "\n",
        "When order does not matter:\n",
        "\n",
        "$$\n",
        "p(x_1,\\dots,x_n)\n",
        "=\n",
        "\\int \\prod_i p(x_i\\mid \\theta)\\, dp(\\theta)\n",
        "$$\n",
        "\n",
        "This is de Finetti’s theorem.\n",
        "\n",
        "Meaning:\n",
        "\n",
        "- dependency is factored through a latent variable  \n",
        "\n",
        "Massive implication:\n",
        "\n",
        "- Bayesian models  \n",
        "- hierarchical models  \n",
        "- modern foundation of probabilistic learning  \n",
        "\n",
        "---\n",
        "\n",
        "## 9. Temporal Factorization\n",
        "\n",
        "Time introduces structure:\n",
        "\n",
        "$$\n",
        "p(x_{1:T})\n",
        "=\n",
        "p(x_1)\\prod_{t=2}^{T} p(x_t \\mid x_{t-1})\n",
        "$$\n",
        "\n",
        "This is:\n",
        "\n",
        "- Markov assumption  \n",
        "- dynamic programming friendly  \n",
        "\n",
        "Extensions:\n",
        "\n",
        "- higher-order Markov  \n",
        "- hidden states  \n",
        "- state-space models  \n",
        "\n",
        "---\n",
        "\n",
        "## 10. Spatial and Locality-Based Factorization\n",
        "\n",
        "Used in:\n",
        "\n",
        "- physics  \n",
        "- vision  \n",
        "- grids  \n",
        "\n",
        "Assumption: variables interact locally\n",
        "\n",
        "$$\n",
        "p(x)\\propto \\prod_{\\langle i,j\\rangle}\\psi(x_i,x_j)\n",
        "$$\n",
        "\n",
        "This is how:\n",
        "\n",
        "- Ising models  \n",
        "- image priors  \n",
        "- CNN-inspired probabilistic models work  \n",
        "\n",
        "---\n",
        "\n",
        "## 11. Autoregressive Factorization\n",
        "\n",
        "Instead of assuming independence, we choose an order:\n",
        "\n",
        "$$\n",
        "p(x)=\\prod_i p(x_i \\mid x_{<i})\n",
        "$$\n",
        "\n",
        "Properties:\n",
        "\n",
        "- exact likelihood  \n",
        "- no independence assumption  \n",
        "- still tractable if conditionals are simple  \n",
        "\n",
        "Used in:\n",
        "\n",
        "- language models  \n",
        "- pixel models  \n",
        "- sequence generators  \n",
        "\n",
        "---\n",
        "\n",
        "## 12. Latent Variable Factorization\n",
        "\n",
        "Introduce hidden variables $z$:\n",
        "\n",
        "$$\n",
        "p(x)=\\int p(x\\mid z)p(z)\\,dz\n",
        "$$\n",
        "\n",
        "Why this helps:\n",
        "\n",
        "- high-dimensional dependencies become conditional independence  \n",
        "- explains correlation via shared cause  \n",
        "\n",
        "This is:\n",
        "\n",
        "- mixture models  \n",
        "- VAEs  \n",
        "- topic models  \n",
        "\n",
        "---\n",
        "\n",
        "## 13. Mean-Field Factorization (Approximate)\n",
        "\n",
        "When exact factorization is impossible:\n",
        "\n",
        "$$\n",
        "p(x)\\approx \\prod_i q_i(x_i)\n",
        "$$\n",
        "\n",
        "This is not a property of reality, but a computational compromise.\n",
        "\n",
        "Used in:\n",
        "\n",
        "- variational inference  \n",
        "- physics  \n",
        "- large-scale Bayesian systems  \n",
        "\n",
        "---\n",
        "\n",
        "## 14. Factorization via Dynamics\n",
        "\n",
        "Instead of factoring distributions, we factor transitions:\n",
        "\n",
        "$$\n",
        "p(x_T \\mid x_0)=\\prod_t p(x_{t+1}\\mid x_t)\n",
        "$$\n",
        "\n",
        "This converts:\n",
        "\n",
        "- static complexity → sequential simplicity  \n",
        "\n",
        "Foundation of:\n",
        "\n",
        "- diffusion models  \n",
        "- Langevin dynamics  \n",
        "- score-based models  \n",
        "\n",
        "---\n",
        "\n",
        "## 15. Functional Factorization\n",
        "\n",
        "Instead of probabilities, factor:\n",
        "\n",
        "log-probabilities, energies, scores\n",
        "\n",
        "$$\n",
        "\\log p(x)=\\sum_i \\phi_i(x)\n",
        "$$\n",
        "\n",
        "Or:\n",
        "\n",
        "$$\n",
        "\\nabla_x \\log p(x)=\\sum_i s_i(x)\n",
        "$$\n",
        "\n",
        "This avoids normalization entirely.\n",
        "\n",
        "---\n",
        "\n",
        "## 16. What Factorization Really Does\n",
        "\n",
        "Across all forms, factorization:\n",
        "\n",
        "- localizes computation  \n",
        "- turns global integrals into sums  \n",
        "- exposes conditional structure  \n",
        "- enables reuse of information  \n",
        "- makes learning modular  \n",
        "\n",
        "Probability is intractable because it is global.  \n",
        "Factorization makes it local.\n",
        "\n",
        "---\n",
        "\n",
        "## 17. The Deep Meta-Truth\n",
        "\n",
        "All probabilistic models are arguments about which dependencies matter and which can be ignored.\n",
        "\n",
        "Factorization is:\n",
        "\n",
        "- epistemology (what we assume)  \n",
        "- computation (what we can compute)  \n",
        "- modeling (what structure we impose)  \n",
        "\n",
        "---\n",
        "\n",
        "## Final One-Line Synthesis\n",
        "\n",
        "Factorization is the art of replacing an exponential joint belief with a network of small, reusable, local beliefs that reconstruct the same global uncertainty.\n"
      ],
      "metadata": {
        "id": "nVGTDvSd0Giu"
      }
    }
  ]
}